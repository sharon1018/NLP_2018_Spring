{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2\n",
    "#### Noisy-Channel Spelling Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open('C:/Users/asus/Downloads/nlp/big.txt').read()))\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of 'word'.\"\n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Channel Probability'''\n",
    "\n",
    "from collections import Counter\n",
    "with open('C:/Users/asus/Downloads/nlp/count_1edit.txt' ,encoding='utf-8-sig') as f:\n",
    "    line = f.readlines()\n",
    "    \n",
    "\"\"\"Put every line in list\"\"\"\n",
    "line_arr=[]\n",
    "for i in range(len(line)):\n",
    "     if len(line[i])>=2:\n",
    "        line[i]= line[i][:-1].split('\\t')\n",
    "        line_arr.append(line[i])\n",
    "        \n",
    "\"\"\"Get key list\"\"\"\n",
    "k_arr=[]\n",
    "for i in range(len(line_arr)):\n",
    "        k_arr.append(tuple(line_arr[i][0].split('|')))\n",
    "\n",
    "\"\"\"Get value list\"\"\"\n",
    "v_arr=[]\n",
    "for i in range(len(line_arr)):\n",
    "    # replace wierd words\n",
    "    if line_arr[i][-1]=='i|?1' :\n",
    "        line_arr[i][-1] = line_arr[i][-1].replace('i|?1','1')\n",
    "    if line_arr[i][-1]=='a|?1' :\n",
    "        line_arr[i][-1] = line_arr[i][-1].replace('a|?1','1')\n",
    "    if line_arr[i][-1]=='e|?1' :\n",
    "        line_arr[i][-1] = line_arr[i][-1].replace('e|?1','1')\n",
    "    v_arr.append(int(line_arr[i][-1]))\n",
    "\n",
    "\"\"\"Zip them to dict\"\"\"\n",
    "word_dict = dict(zip(k_arr, v_arr))\n",
    "\n",
    "#(w,c)= 1,2,3次的次數\n",
    "Nr = (Counter(word_dict.values()))    #新增n0進去!\n",
    "#w,c 的次數 \n",
    "count_wc = word_dict   #新增n0進去!\n",
    "# 計算每個c出現的次數統計, 產生一個新的dict儲存\n",
    "count_c = dict()   \n",
    "for key, value in (count_wc.items()):\n",
    "    if key[1] in count_c:\n",
    "        count_c[key[1]]+=value\n",
    "    else:\n",
    "        count_c[key[1]]=value   \n",
    "Nall= sum(Nr.values())\n",
    "N0 = 26*26*26*26+2*26*26*26+26*26 - Nall   #沒有出現的組合次數\n",
    "Nr_smooth = [ N0 if r==0 else (r+1)*Nr[r+1] / Nr[r] for r in range(11) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Combining channel probability with word probability to score states'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Pedit(w, c):\n",
    "    if (w,c) not in word_dict: #r=0\n",
    "        if c in count_c:\n",
    "            return Nr_smooth[0]/N0/count_c[c]\n",
    "        else:\n",
    "            return 0\n",
    "    elif count_wc[(w,c)] <= 10:  #需要smooth的\n",
    "        r = count_wc[(w,c)]\n",
    "        return Nr_smooth[r]/count_c[c]\n",
    "#         return (r+1)*Nr[r+1]/Nr[r]/count_c[c]  \n",
    "#         (Ped(w, c) = count1(w, c)/count(c))\n",
    "    else: #>10的\n",
    "        return count_wc[(w,c)]/count_c[c]   #Ped(w, c) = count1(w, c)/count(c)\n",
    "    \n",
    "'''Combining channel probability with word probability to score states'''\n",
    "# def P(pedit, pw):\n",
    "#     return __________________\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_states(state):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    (L, R, edit, prob, pedit) = state\n",
    "    R0, R1 = R[0], R[1:]\n",
    "    all_word=[]\n",
    "    if edit <= 2: \n",
    "#         return ( L+R0, R1, edit, prob, pedit*0.8 )\n",
    "        all_word.append(( L + R0,     R1, edit,   P(L+R0+R1) , Pedit('','') ))      #noedit\n",
    "        all_word.append(( L ,         R1 ,edit+1, P(L+R1),   Pedit(R0,'') ))          #delete\n",
    "        all_word.append((L+R0[1]+R0[0],R1, edit+1,P(L+R0[1]+R0[0]+R1), Pedit(R0[0],R0[1]))\n",
    "                        if len(R0)>1 else (L+R0 , R1, edit+1, P(L+R0+R1), Pedit(R0,R0))) #transpose\n",
    "        for c in letters:\n",
    "            all_word.append((L + c ,    R1, edit+1, P(L+c+R1), Pedit(R0, c) ))        #replace\n",
    "            all_word.append((L + R0 + c,R1, edit+1, P(L+R0+c+R1), Pedit('', c) ))     #insert      \n",
    "        return all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def next_states(state):\n",
    "#     letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "#     L, R, edit, prob = state\n",
    "#     R0, R1 = R[0], R[1:]\n",
    "#     all_word=[]\n",
    "#     if edit<=2: \n",
    "#         all_word.append((    L + R0,     R1, edit,   P(L+R0+R1) ))      #noedit\n",
    "#         all_word.append((    L ,         R1 ,edit+1, P(L+R1)))          #delete\n",
    "#         for c in letters:\n",
    "#             all_word.append((L + c ,     R1, edit+1, P(L+c+R1)))        #replace\n",
    "#             all_word.append((L + R0 + c, R1, edit+1, P(L+R0+c+R1)))     #insert      \n",
    "#         return all_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word):\n",
    "    states = [ (\"\", word, 0, 0, 0) ]\n",
    "    for i in range(len(word)):\n",
    "        states = [ states for state in states for states in next_states(state)]\n",
    "        states = list(set(states))\n",
    "        states = sorted(states, key=lambda x: (x[2],x[3]*(-1)))[:800]\n",
    "    return pprint(sorted(states, key=lambda x: x[3]*(-1))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apparent', '', 1, 3.764840868244015e-05),\n",
      " ('apparent', '', 2, 3.764840868244015e-05),\n",
      " ('apparant', '', 0, 0.0),\n",
      " ('appsrant', '', 1, 0.0),\n",
      " ('apparan', '', 1, 0.0)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test result\"\"\"\n",
    "word = 'apparant'\n",
    "print(correction(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"count_wc<=10的替換成Nr_2 = count1_wc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Pedit(w, c):\n",
    "#     if count_c[c]>0\n",
    "#         if (w,c) not in word_dict:  \n",
    "# #          return new_count[0]/count_c\n",
    "# #         elif :\n",
    "# #           return new_count(w,c)/count_c[c]\n",
    "# #     else:   #沒出現過的\n",
    "# #         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXBEAM = 500\n",
    "def correction(word):\n",
    "    states = [ ('', word, [], Pw(word), 1) ] # initial state\n",
    "    for i in range(len(word)):\n",
    "        print(i, states[:3])\n",
    "        states = [newstates for state in states for newstates in next_states(state)]\n",
    "        states = [state     for state in states if __________________]\n",
    "        \n",
    "        temp = defaultdict(list)\n",
    "        for state in states:\n",
    "            L, R, edits, pw, pedit = state\n",
    "            temp[L+R].append(state)\n",
    "        states = [min(substates, key=lambda x: len(x[2])) for wd, substates in temp.items()]\n",
    "        \n",
    "        states = sorted(states, key=__________________)[:MAXBEAM]\n",
    "        \n",
    "    states = [state for state in states if __________________]\n",
    "    \n",
    "    return sorted(states, key=__________________)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def P(pedit, pw): ??\n",
    "new_states ?\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    " temp = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
