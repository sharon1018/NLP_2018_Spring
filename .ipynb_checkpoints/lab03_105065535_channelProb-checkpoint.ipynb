{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab02\n",
    "### Noisy-Channel Spelling Check\n",
    "• Pdel(x|xy) = count (xy typed as x) / count(xy) = count (x|xy ) / count(xy) <br/>\n",
    "• Pins(xy|x) = count(x typed as xy) / count(x) = count(xy|x) / count(x) <br/>\n",
    "• Psub(y|x) = count (x typed as y) / count(x) = count(y|x) / count(x)  <br/>\n",
    "• Ptrans(yx|xy) = count(xy typed as yx) / count(xy) = count(yx|xy) / count(xy) <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the probability function P(wrong, correct) as follows:<br/>\n",
    "- argmaxcP(c|w) = argmaxcP(w|c)P(c)/P(w) = argmaxcP(w|c)P(c) because P(w) is constant<br/>\n",
    "- Nr = distinct_number(w, c where count(w, c) = r >= 1)<br/>\n",
    "- Nall = N1 + N2 + N3 + ...<br/>\n",
    "- N0 = 26 ∗ 26 ∗ 26 ∗ 26 + 2 ∗ 26 ∗ 26 ∗ 26 + 26 ∗ 26 − Nall<br/>\n",
    "- count1(w, c) = (r + 1) ∗ Nr+1/Nr<br/>\n",
    "- if 0 <= count(w, c) = r <= 10<br/>\n",
    "- Ped(w, c) = count1(w, c)/count(c)<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "'''Word Probability'''\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "count_word = Counter(words(open('C:/Users/asus/Downloads/nlp/big.txt').read()))\n",
    "Nw = sum(count_word.values())\n",
    "Pdist = {word: float(count)/Nw for word, count in count_word.items()}\n",
    "\n",
    "def Pw(word): \n",
    "    return Pdist[word] if word in Pdist else 10/10**len(word)/Nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586\n"
     ]
    }
   ],
   "source": [
    "'''Channel Probability'''\n",
    "from collections import Counter\n",
    "with open('C:/Users/asus/Downloads/nlp/count_1edit.txt' ,encoding='UTF-8-sig') as f:\n",
    "    line = f.readlines()\n",
    "    \n",
    "\"\"\"Put every line in list\"\"\"\n",
    "line_arr=[]\n",
    "for i in range(len(line)):\n",
    "     if len(line[i])>=2:\n",
    "        line[i]= line[i][:-1].split('\\t')\n",
    "        line_arr.append(line[i])\n",
    "        \n",
    "\"\"\"Get key list\"\"\"\n",
    "k_arr=[]\n",
    "for i in range(len(line_arr)):\n",
    "        k_arr.append(tuple(line_arr[i][0].split('|')))\n",
    "\n",
    "\"\"\"Get value list\"\"\"\n",
    "v_arr=[]\n",
    "for i in range(len(line_arr)):\n",
    "    # replace wierd words\n",
    "    if line_arr[i][-1]=='' :\n",
    "        print(i)\n",
    "#         line_arr[i][-1] = line_arr[i][-1].replace('i|?1','1')\n",
    "#     if line_arr[i][-1]=='a|?1' :\n",
    "#         print(i)\n",
    "#         line_arr[i][-1] = line_arr[i][-1].replace('a|?1','1')\n",
    "#     if line_arr[i][-1]=='e|?1' :\n",
    "#         line_arr[i][-1] = line_arr[i][-1].replace('e|?1','1')\n",
    "    else:\n",
    "        v_arr.append(int(line_arr[i][-1]))\n",
    "\n",
    "\"\"\"Zip them to dict\"\"\"\n",
    "word_dict = dict(zip(k_arr, v_arr))\n",
    "\n",
    "#(w,c)= 1,2,3次的次數\n",
    "Nr = (Counter(word_dict.values()))    #新增n0進去!\n",
    "#w,c 的次數 \n",
    "count_wc = word_dict   #新增n0進去!\n",
    "# 計算每個c出現的次數統計, 產生一個新的dict儲存\n",
    "count_c = dict()   \n",
    "for key, value in (count_wc.items()):\n",
    "    if key[1] in count_c:\n",
    "        count_c[key[1]]+=value\n",
    "    else:\n",
    "        count_c[key[1]]=value   \n",
    "Nall= sum(Nr.values())\n",
    "N0 = 26*26*26*26+2*26*26*26+26*26 - Nall   #沒有出現的組合次數\n",
    "Nr_smooth = [ N0 if r==0 else (r+1)*Nr[r+1] / Nr[r] for r in range(11) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pedit(w, c):\n",
    "    if (w,c) not in word_dict: #r=0\n",
    "        if c in count_c:         #有在正確的list中\n",
    "            return 317/N0/count_c[c]\n",
    "        else:\n",
    "            return 0\n",
    "    elif 0<count_wc[(w,c)] <= 10:  #需要smooth的\n",
    "        r = count_wc[(w,c)]\n",
    "        return Nr_smooth[r]/count_c[c]\n",
    "#         return (r+1)*Nr[r+1]/Nr[r]/count_c[c]  \n",
    "#         (Ped(w, c) = count1(w, c)/count(c))\n",
    "    else:      #>10的\n",
    "        return count_wc[(w,c)]/count_c[c]   #Ped(w, c) = count1(w, c)/count(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_states(state):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    (L, R, edit, prob, pedit) = state\n",
    "    all_word=[]\n",
    "\n",
    "    R0, R1 = R[0:1], R[1:]\n",
    "    if edit == 2:  \n",
    "        return [( L + R0,     R1, edit,   Pw(L+R0+R1) , pedit)]\n",
    "    else:\n",
    "        all_word.append(( L + R0,     R1, edit,   Pw(L+R0+R1) , pedit))            #noedit\n",
    "        all_word.append(( L ,         R1 ,edit+1, Pw(L+R1),     pedit* Pedit(L[-1:]+R0,L[-1:]) ))  #delete\n",
    "        all_word.append(( L+ R1[0], R0+R1[1:], edit+1,Pw(L+ R1[0]+ R0+R1[1:]),pedit* Pedit(R0+R1[0],R1[0]+R0))\n",
    "                        if len(R0)>1 else (L+R1 , R0, edit+1, Pw(L+R0+R1),    pedit*Pedit(R0+R1, R1+R0))) #transpose\n",
    "        for c in letters:\n",
    "            all_word.append((L + c ,    R1, edit+1, Pw(L+c+R1),    pedit*Pedit(R0, c) )) #replace\n",
    "            all_word.append((L + R0 + c,R1, edit+1, Pw(L+R0+c+R1), pedit*Pedit(R0, R0+c) )) #insert      \n",
    "        return all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" small edit and large probability, 最後取機率大的 \"\"\"\n",
    "\n",
    "def correction(word):\n",
    "    states = [ (\"\", word, 0, 0, 1) ]\n",
    "    for i in range(len(word)):\n",
    "        states = [ states for state in states for states in next_states(state)]\n",
    "#         states = list(set(states))\n",
    "#         states = sorted(states, key=lambda x: (x[2]))[:1000]\n",
    "     \n",
    "    temp = defaultdict(list)\n",
    "    for state in states:\n",
    "        L, R, edits, pw, pedit = state\n",
    "        temp[L+R].append(state)  #L+R相同的選state裡edit最小的\n",
    "    states = [min(substates, key=lambda x: (x[2],x[3]*x[4]*(-1))) for wd, substates in temp.items()]\n",
    "    \n",
    "## state[2]==0的取出 sort\n",
    "    states0 = [state for state in states if states[2]==0]\n",
    "    states0 = sorted(states0, key=lambda x: -1*x[3]*x[4])\n",
    "    \n",
    "## state[2]!=0的另外分類    \n",
    "    states_ = [state for state in states if states[2]!=0]\n",
    "    states_ = sorted(states_, key=lambda x: -1*x[3]*x[4])\n",
    "    \n",
    "    states = (states0 + states_)[:500]\n",
    "\n",
    "    return sorted(states, key=lambda x: ((-1)*x[3]*x[4],(-1)*x[3]))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('speaking', '', 2, 0.00016583227633931973, 0.01929828387012364),\n",
       " ('spelling', '', 1, 3.585562731660967e-06, 0.5714285714285714),\n",
       " ('spoiling', '', 2, 6.2747347804066925e-06, 0.23109879032258063)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test result\"\"\"\n",
    "correction('speling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apparent', '', 1, 3.764840868244015e-05, 0.2371191135734072),\n",
       " ('apparant', '', 0, 8.963906829152418e-14, 1),\n",
       " ('apparan', '', 1, 8.963906829152418e-13, 0.08217592592592593)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('apparant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('running', '', 1, 0.00012549469560813384, 0.9130434782608695),\n",
       " ('ruining', '', 1, 2.6891720487457255e-06, 0.8454545454545455),\n",
       " ('turning', '', 2, 0.0001864492620463703, 0.010493542435424354)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('runing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thanks', '', 1, 3.495923663369443e-05, 0.2820030120481928),\n",
       " ('thinks', '', 1, 2.2409767072881046e-05, 0.3411458333333333),\n",
       " ('think', '', 2, 0.0004992896103837897, 0.013568300189393938)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('thenks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
